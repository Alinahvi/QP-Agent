#!/usr/bin/env python3
"""
Comprehensive MCP Server for Agent Integration
Handles multiple tool types: Open Pipe, KPI, Content Search, SME Search, Workflow, Future Pipeline
"""

import json
import logging
import re
import os
import argparse
import requests
from typing import Dict, Any, Optional, List
from dataclasses import dataclass
from flask import Flask, request, jsonify
from dotenv import load_dotenv

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class ToolRequest:
    """Base request structure"""
    tool: str
    args: Dict[str, Any]

class ComprehensiveRouter:
    """Router for multiple tool types"""
    
    def __init__(self):
        # Tool detection patterns
        self.tool_patterns = {
            'open_pipe_analyze': [
                r'open pipe', r'pipeline', r'opportunities', r'opps', r'products.*filter',
                r'passed stage', r'post stage', r'stage \d+'
            ],
            'kpi_analyze': [
                r'kpi', r'key performance', r'performance analysis', r'metrics',
                r'quarterly results', r'performance indicators', r'avg calls', r'average calls',
                r'calls.*germany', r'calls.*break.*down', r'ramping.*aes', r'ramp.*status',
                r'coverage', r'meetings', r'acv', r'pipeline generation', r'call connections',
                r'meeting statistics', r'performance.*germany', r'performance.*us',
                r'compare.*coverage', r'this month', r'last year', r'break.*down',
                r'slow ramping', r'fast ramping', r'ramp.*analysis',
                r'trends', r'meeting trends', r'performance trends', r'improvement',
                r'call connection improvement', r'management tier', r'management level',
                r'performance by management', r'management performance'
            ],
            'content_search': [
                r'content search', r'search.*content', r'find.*article', r'knowledge',
                r'search.*topic', r'content.*topic', r'act.*course', r'consensus.*demo',
                r'show.*act', r'list.*act', r'find.*act', r'act.*curricula', r'act.*assets',
                r'consensus.*demo', r'consensus.*video', r'consensus.*preview',
                r'course.*related', r'course.*created', r'course.*completion', r'course.*enrollment',
                r'demo.*video', r'demo.*created', r'demo.*preview', r'demo.*access',
                r'curricula.*completion', r'assets.*tagged', r'assets.*created',
                r'top.*course', r'course.*enrollment', r'course.*completion.*rate',
                r'completion.*rate', r'enrollment.*student', r'created.*between',
                r'created.*last', r'created.*quarter', r'created.*year',
                r'tagged.*with', r'preview.*link', r'public.*access', r'completion.*tracking',
                r'find.*content.*about', r'content.*about', r'articles.*on', r'courses.*on',
                r'search.*for.*content', r'look.*for.*content', r'get.*content',
                r'documentation', r'look.*for.*documentation', r'get.*documentation',
                r'retail industry', r'retail.*solutions', r'management training', r'leadership development',
                r'strategic planning', r'planning resources', r'industry solutions', r'management content'
            ],
            'sme_search': [
                r'sme', r'subject matter expert', r'expert search', r'find.*expert',
                r'who.*expert', r'expertise', r'search.*for.*expert', r'find.*sme',
                r'look.*for.*expert', r'get.*expert', r'who.*knows', r'experts.*on',
                r'specialist', r'consultant', r'advisor', r'leadership coaches',
                r'coaches', r'product expert', r'product specialist', r'technical expert'
            ],
            'workflow': [
                r'workflow', r'process', r'procedure', r'step.*by.*step',
                r'how.*to', r'guide'
            ],
            'future_pipeline': [
                r'future pipeline', r'pipeline generation', r'generate.*pipeline',
                r'create.*pipeline', r'new.*pipeline', r'cross-sell.*opportunities',
                r'upsell.*opportunities', r'renewal.*opportunities', r'most valuable.*product',
                r'highest amount.*opportunity', r'highest amount.*renewal', r'how many.*opportunities',
                r'which product.*highest', r'generate.*for.*cross-sell', r'generate.*for.*upsell',
                r'generate.*for.*renewal', r'show.*opportunities', r'find.*opportunities',
                r'top.*renewal.*product', r'renewal.*product', r'products.*for', r'opportunities.*for',
                r'what.*are.*the.*top', r'which.*products', r'best.*products',
                r'potential', r'upsell.*potential', r'highest.*value', r'value.*products',
                r'value.*opportunities', r'create.*upsell', r'show.*upsell', r'upsell.*for'
            ]
        }
        
        # OU patterns
        self.ou_patterns = {
            r'AMER\s+ACC(?:\s+OU)?': 'AMER ACC',
            r'AMER-ACC': 'AMER ACC',
            r'ACC\s+in\s+AMER': 'AMER ACC',
            r'EMEA\s+ENTR(?:AISE)?': 'EMEA ENTR',
            r'EMEA-ENTR': 'EMEA ENTR',
            r'Enterprise\s+EMEA': 'EMEA ENTR',
            r'SMB\s*-\s*AMER\s+SMB': 'SMB - AMER SMB',
            r'SMB\s*-\s*EMEA\s+SMB': 'SMB - EMEA SMB',
            r'UKI': 'UKI',
            r'LATAM': 'LATAM',
            r'ANZ': 'ANZ',
            r'APAC': 'APAC',
            r'AMER': 'AMER'
        }
        
        # Country mapping
        self.country_mapping = {
            'US': 'United States',
            'USA': 'United States',
            'UK': 'United Kingdom',
            'UAE': 'United Arab Emirates',
        }

    def detect_tool(self, text: str) -> Optional[str]:
        """Detect which tool to use based on text"""
        text_lower = text.lower()
        
        # Check for future pipeline first (higher priority)
        if any(re.search(pattern, text_lower) for pattern in self.tool_patterns['future_pipeline']):
            return 'future_pipeline'
        
        # Check for other tools
        for tool, patterns in self.tool_patterns.items():
            if tool == 'future_pipeline':  # Skip future_pipeline as it's already checked
                continue
            for pattern in patterns:
                if re.search(pattern, text_lower):
                    print(f"DEBUG: Matched pattern '{pattern}' for tool '{tool}' in text '{text_lower}'")
                    return tool
        
        print(f"DEBUG: No tool detected for text '{text_lower}'")
        return None

    def extract_ou_name(self, text: str) -> Optional[str]:
        """Extract OU name from text"""
        text_upper = text.upper()
        
        # First, try to find explicit OU patterns
        for pattern, ou_name in self.ou_patterns.items():
            match = re.search(pattern, text_upper)
            if match:
                return ou_name
        
        # Check for "by country" patterns
        if 'BY COUNTRY' in text_upper or 'RATES BY COUNTRY' in text_upper:
            return 'AMER ACC'  # Default OU for multi-country queries
        
        # If no explicit OU found, try to infer from country/region
        country_ou_mapping = {
            'GERMANY': 'EMEA ENTR',
            'US': 'AMER ACC', 
            'USA': 'AMER ACC',
            'UNITED STATES': 'AMER ACC',
            'UK': 'UKI',
            'UNITED KINGDOM': 'UKI',
            'FRANCE': 'EMEA ENTR',
            'CANADA': 'AMER ACC',
            'AUSTRALIA': 'ANZ',
            'JAPAN': 'APAC',
            'EMEA': 'EMEA ENTR',
            'AMER': 'AMER ACC',
            'APAC': 'APAC'
        }
        
        for country, ou_name in country_ou_mapping.items():
            if country in text_upper:
                return ou_name
                
        return None

    def extract_country(self, text: str) -> Optional[str]:
        """Extract country from text"""
        # Check for "by country" patterns first
        if re.search(r'by\s+country|rates\s+by\s+country', text, re.IGNORECASE):
            return "MULTIPLE_COUNTRIES"
            
        country_patterns = [
            r'country\s*=\s*([A-Za-z\s]+?)(?:\s|$)',
            r'in\s+([A-Za-z\s]+?)(?:\s+country|\s+top|\s+for|\s+within|\s+passed|\s+post|\s+stage|\s+quarter|\s+open|\s+pipe|\s+products|\s+filter|\s+show|\s+compare|\s+where|\s+and|\s+order|\s+by|\s+amount|\s+stage|\s+in|\s+\(|\s+\)|\s+>|\s+<|\s+=|\s+$|$)',
        ]
        
        for pattern in country_patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                country = match.group(1).strip()
                country = re.sub(r'\s+', ' ', country)
                if len(country) > 50:
                    continue
                if country.upper() in ['AMER ACC', 'EMEA ENTR', 'UKI', 'LATAM', 'ANZ']:
                    continue
                return self.country_mapping.get(country, country)
        
        if 'country = US' in text or 'country=US' in text:
            return "United States"
        
        return None

    def extract_min_stage(self, text: str) -> Optional[int]:
        """Extract minimum stage from text"""
        text_lower = text.lower()
        stage_patterns = {
            r'post\s+stage\s+(\d+)': lambda m: int(m.group(1)),
            r'passed\s+stage\s+(\d+)': lambda m: int(m.group(1)),
            r'>=?\s*stage\s+(\d+)': lambda m: int(m.group(1)),
            r'stage\s+(\d+)\s*and\s+above': lambda m: int(m.group(1)),
            r'stage\s+(\d+)\+': lambda m: int(m.group(1)),
        }
        
        for pattern, extractor in stage_patterns.items():
            match = re.search(pattern, text_lower)
            if match:
                return extractor(match)
        return None

    def extract_timeframe(self, text: str) -> str:
        """Extract timeframe from text"""
        text_lower = text.lower()
        timeframe_patterns = {
            r'this\s+quarter': 'CURRENT',
            r'current\s+quarter': 'CURRENT',
            r'current': 'CURRENT',
            r'last\s+quarter': 'PREVIOUS',
            r'previous\s+quarter': 'PREVIOUS',
            r'previous': 'PREVIOUS',
        }
        
        for pattern, timeframe in timeframe_patterns.items():
            if re.search(pattern, text_lower):
                return timeframe
        return "CURRENT"

    def extract_products(self, text: str) -> Optional[str]:
        """Extract product list from text"""
        product_patterns = [
            r'filter\s+to\s+([^,]+(?:,\s*[^,]+)*)',
            r'products?\s*:\s*([^,]+(?:,\s*[^,]+)*)',
            r'include\s+([^,]+(?:,\s*[^,]+)*)',
            r'([A-Za-z\s]+(?:\s+Cloud)?)\s+and\s+([A-Za-z\s]+(?:\s+Cloud)?)',
        ]
        
        for pattern in product_patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                if len(match.groups()) == 2:
                    products = f"{match.group(1).strip()}, {match.group(2).strip()}"
                else:
                    products = match.group(1).strip()
                products = re.sub(r'\s+', ' ', products)
                return products
        
        if 'data cloud' in text.lower() and 'sales cloud' in text.lower():
            return "Data Cloud, Sales Cloud"
        
        return None

    def extract_limit(self, text: str) -> int:
        """Extract limit from text"""
        limit_patterns = [
            r'top\s+(\d+)',
            r'show\s+(\d+)',
            r'limit\s+(\d+)',
            r'first\s+(\d+)',
        ]
        
        for pattern in limit_patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                limit = int(match.group(1))
                return min(limit, 50)
        return 10

    def extract_topic(self, text: str) -> Optional[str]:
        """Extract topic for content search"""
        topic_patterns = [
            r'topic[:\s]+([^,]+)',
            r'search.*for\s+([^,]+)',
            r'find.*about\s+([^,]+)',
            r'content.*about\s+([^,]+)',
            r'on\s+([^,]+?)(?:\s|$)',  # For "on AI and machine learning"
            r'about\s+([^,]+?)(?:\s|$)',  # For "about Service Cloud implementation"
            r'articles\s+on\s+(.+)$',  # For "articles on AI and machine learning" - capture everything to end
            r'about\s+(.+)$',  # For "about Service Cloud implementation" - capture everything to end
        ]
        
        for pattern in topic_patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                topic = match.group(1).strip()
                return topic
        
        # Look for common topics
        if 'data cloud' in text.lower():
            return 'Data Cloud'
        if 'sales cloud' in text.lower():
            return 'Sales Cloud'
        if 'service cloud' in text.lower():
            return 'Service Cloud'
        if 'ai' in text.lower() and 'machine learning' in text.lower():
            return 'AI and machine learning'
        
        return None

    def extract_source(self, text: str) -> str:
        """Extract source for content search"""
        text_lower = text.lower()
        if 'course' in text_lower:
            return 'Course'
        elif 'asset' in text_lower:
            return 'Asset'
        elif 'curriculum' in text_lower:
            return 'Curriculum'
        elif 'act' in text_lower:
            return 'Course'  # Map ACT to Course
        elif 'quip' in text_lower:
            return 'Asset'   # Map QUIP to Asset
        return 'Course'  # Default to Course

    def extract_region(self, text: str) -> Optional[str]:
        """Extract region for SME search"""
        region_patterns = [
            r'region[:\s]+([^,]+)',
            r'in\s+([A-Z]{2,4})',
            r'for\s+([A-Z]{2,4})',
        ]
        
        for pattern in region_patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                region = match.group(1).strip().upper()
                return region
        
        return None

    def extract_expertise(self, text: str) -> Optional[str]:
        """Extract expertise area for SME search"""
        expertise_patterns = [
            r'expert.*in\s+([^,]+)',
            r'expertise[:\s]+([^,]+)',
            r'skilled.*in\s+([^,]+)',
        ]
        
        for pattern in expertise_patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                expertise = match.group(1).strip()
                return expertise
        
        return None

    def extract_opportunity_type(self, text: str) -> Optional[str]:
        """Extract opportunity type for future pipeline"""
        text_lower = text.lower()
        
        if 'cross-sell' in text_lower or 'cross sell' in text_lower:
            return 'cross-sell'
        elif 'upsell' in text_lower or 'up-sell' in text_lower:
            return 'upsell'
        elif 'renewal' in text_lower:
            return 'renewal'
        
        return None

    def extract_segment(self, text: str) -> Optional[str]:
        """Extract segment for future pipeline"""
        text_lower = text.lower()
        
        if 'enterprise' in text_lower:
            return 'enterprise'
        elif 'mid-market' in text_lower or 'mid market' in text_lower:
            return 'mid-market'
        elif 'small business' in text_lower or 'sme' in text_lower:
            return 'small business'
        
        return None

    def extract_product(self, text: str) -> Optional[str]:
        """Extract product for future pipeline"""
        text_lower = text.lower()
        
        if 'data cloud' in text_lower:
            return 'Data Cloud'
        elif 'sales cloud' in text_lower:
            return 'Sales Cloud'
        elif 'service cloud' in text_lower:
            return 'Service Cloud'
        elif 'marketing cloud' in text_lower:
            return 'Marketing Cloud'
        
        return None

    def route_request(self, text: str) -> Dict[str, Any]:
        """Route natural language request to appropriate tool"""
        
        # Detect tool
        tool = self.detect_tool(text)
        if not tool:
            return {
                "error": "Could not determine the appropriate tool for this request. Please be more specific about what you want to do."
            }
        
        # Extract common parameters
        ou_name = self.extract_ou_name(text)
        country = self.extract_country(text)
        timeframe = self.extract_timeframe(text)
        limit = self.extract_limit(text)
        
        # Build args based on tool type
        args = {}
        
        if tool == 'open_pipe_analyze':
            if not ou_name:
                return {"error": "Operating Unit (ouName) is required for open pipe analysis. Please specify an OU like 'AMER ACC' or 'EMEA ENTR'."}
            
            args = {
                "ouName": ou_name,
                "timeFrame": timeframe,
                "limitN": limit
            }
            
            if country:
                args["country"] = country
            
            min_stage = self.extract_min_stage(text)
            if min_stage is not None:
                args["minStage"] = min_stage
            
            products = self.extract_products(text)
            if products:
                args["productListCsv"] = products
        
        elif tool == 'kpi_analyze':
            # If no explicit OU found, try to infer from country/region
            if not ou_name:
                country_ou_mapping = {
                    'GERMANY': 'EMEA ENTR',
                    'US': 'AMER ACC', 
                    'USA': 'AMER ACC',
                    'UNITED STATES': 'AMER ACC',
                    'UK': 'UKI',
                    'UNITED KINGDOM': 'UKI',
                    'FRANCE': 'EMEA ENTR',
                    'CANADA': 'AMER ACC',
                    'AUSTRALIA': 'ANZ',
                    'JAPAN': 'APAC',
                    'EMEA': 'EMEA ENTR',
                    'AMER': 'AMER ACC',
                    'APAC': 'APAC',
                    'MULTIPLE_COUNTRIES': 'AMER ACC'  # Default OU for multi-country queries
                }
                
                text_upper = text.upper()
                
                # Check for "by country" patterns first
                if 'BY COUNTRY' in text_upper or 'RATES BY COUNTRY' in text_upper:
                    ou_name = 'AMER ACC'  # Default OU for multi-country queries
                else:
                    for country_key, ou_value in country_ou_mapping.items():
                        if country_key in text_upper:
                            ou_name = ou_value
                            break
                
                # If still no OU found, return error
                if not ou_name:
                    return {"error": "Operating Unit (ouName) is required for KPI analysis. Please specify an OU like 'AMER ACC' or 'EMEA ENTR'."}
            
            args = {
                "ouName": ou_name,
                "timeFrame": timeframe
            }
            
            if country:
                args["country"] = country
        
        elif tool == 'content_search':
            topic = self.extract_topic(text)
            if not topic:
                return {"error": "Please specify a topic to search for (e.g., 'Data Cloud', 'Sales Cloud')."}
            
            args = {
                "topic": topic,
                "source": self.extract_source(text)
            }
        
        elif tool == 'sme_search':
            region = self.extract_region(text)
            expertise = self.extract_expertise(text)
            
            if not region and not expertise:
                return {"error": "Please specify a region or expertise area for SME search."}
            
            args = {}
            if region:
                args["region"] = region
            if expertise:
                args["expertise"] = expertise
        
        elif tool == 'workflow':
            args = {
                "process": "general",
                "context": text
            }
        
        elif tool == 'future_pipeline':
            if not ou_name:
                return {"error": "Operating Unit (ouName) is required for pipeline generation. Please specify an OU like 'AMER ACC' or 'EMEA ENTR'."}
            
            args = {
                "ouName": ou_name,
                "timeFrame": timeframe
            }
            
            # Extract opportunity type
            opportunity_type = self.extract_opportunity_type(text)
            if opportunity_type:
                args["opportunityType"] = opportunity_type
            
            # Extract product
            product = self.extract_product(text)
            if product:
                args["product"] = product
            
            # Extract segment
            segment = self.extract_segment(text)
            if segment:
                args["segment"] = segment
            
            # Extract limit
            limit = self.extract_limit(text)
            if limit != 10:  # Only add if not default
                args["limit"] = limit
        
        return {
            "tool": tool,
            "args": args
        }

class ComprehensiveMCPServer:
    """Comprehensive MCP Server for multiple tool types"""
    
    def __init__(self, dry_run: bool = True, sf_base_url: str = None, sf_access_token: str = None):
        self.router = ComprehensiveRouter()
        self.dry_run = dry_run
        self.sf_base_url = sf_base_url
        self.sf_access_token = sf_access_token
        self.app = Flask(__name__)
        self._setup_routes()
    
    def _setup_routes(self):
        """Setup Flask routes"""
        
        @self.app.route('/health', methods=['GET'])
        def health():
            return jsonify({
                "status": "healthy",
                "service": "comprehensive-mcp",
                "dry_run": self.dry_run,
                "sf_configured": bool(self.sf_base_url and self.sf_access_token),
                "supported_tools": list(self.router.tool_patterns.keys())
            })
        
        @self.app.route('/route', methods=['POST'])
        def route():
            try:
                data = request.get_json()
                if not data or 'text' not in data:
                    return jsonify({"error": "No text provided"}), 400
                
                # Route the request
                result = self.router.route_request(data['text'])
                return jsonify(result)
                
            except Exception as e:
                logger.error(f"Error in route endpoint: {e}")
                return jsonify({"error": str(e)}), 500
        
        @self.app.route('/analyze', methods=['POST'])
        def analyze():
            try:
                data = request.get_json()
                if not data:
                    return jsonify({"error": "No JSON data provided"}), 400
                
                # Route the request to determine tool type
                tool_result = self.router.route_request(data.get('text', ''))
                if 'error' in tool_result:
                    return jsonify(tool_result)
                
                # Execute the appropriate tool
                tool_name = tool_result.get('tool')
                tool_args = tool_result.get('args', {})
                
                if tool_name == 'open_pipe_analyze':
                    result = self.open_pipe_analyze(**tool_args)
                elif tool_name == 'kpi_analyze':
                    result = self.kpi_analyze(**tool_args)
                elif tool_name == 'content_search':
                    result = self.content_search(**tool_args)
                elif tool_name == 'sme_search':
                    result = self.sme_search(**tool_args)
                elif tool_name == 'workflow':
                    result = self.workflow(**tool_args)
                elif tool_name == 'future_pipeline':
                    result = self.future_pipeline(**tool_args)
                else:
                    result = {"error": f"Unknown tool: {tool_name}"}
                
                return jsonify(result)
                
            except Exception as e:
                logger.error(f"Error in analyze endpoint: {e}")
                return jsonify({"error": str(e)}), 500
    
    def open_pipe_analyze(self, **kwargs):
        """Open pipe analysis tool"""
        if self.dry_run:
            return {
                "status": "success",
                "message": "Open Pipe Analysis completed (DRY RUN)",
                "parameters": kwargs,
                "note": "This is a dry run. Set DRY_RUN=false to call Salesforce."
            }
        else:
            return self._call_salesforce_endpoint('openPipeAnalyze', kwargs)
    
    def kpi_analyze(self, **kwargs):
        """KPI analysis tool"""
        if self.dry_run:
            return {
                "status": "success",
                "message": "KPI Analysis completed (DRY RUN)",
                "parameters": kwargs,
                "note": "This is a dry run. Set DRY_RUN=false to call Salesforce."
            }
        else:
            return self._call_salesforce_endpoint('kpiAnalyze', kwargs)
    
    def content_search(self, **kwargs):
        """Content search tool"""
        if self.dry_run:
            return {
                "status": "success",
                "message": "Content Search completed (DRY RUN)",
                "parameters": kwargs,
                "note": "This is a dry run. Set DRY_RUN=false to call Salesforce."
            }
        else:
            return self._call_salesforce_endpoint('contentSearch', kwargs)
    
    def sme_search(self, **kwargs):
        """SME search tool"""
        if self.dry_run:
            return {
                "status": "success",
                "message": "SME Search completed (DRY RUN)",
                "parameters": kwargs,
                "note": "This is a dry run. Set DRY_RUN=false to call Salesforce."
            }
        else:
            return self._call_salesforce_endpoint('smeSearch', kwargs)
    
    def workflow(self, **kwargs):
        """Workflow tool"""
        if self.dry_run:
            return {
                "status": "success",
                "message": "Workflow completed (DRY RUN)",
                "parameters": kwargs,
                "note": "This is a dry run. Set DRY_RUN=false to call Salesforce."
            }
        else:
            return self._call_salesforce_endpoint('workflow', kwargs)
    
    def future_pipeline(self, **kwargs):
        """Future pipeline tool"""
        if self.dry_run:
            return {
                "status": "success",
                "message": "Future Pipeline completed (DRY RUN)",
                "parameters": kwargs,
                "note": "This is a dry run. Set DRY_RUN=false to call Salesforce."
            }
        else:
            return self._call_salesforce_endpoint('futurePipeline', kwargs)
    
    def _call_salesforce_endpoint(self, endpoint_name, params):
        """Call Salesforce Apex REST endpoint"""
        try:
            if not self.sf_base_url or not self.sf_access_token:
                return {"error": "Salesforce configuration missing. Check SF_BASE_URL and SF_ACCESS_TOKEN."}
            
            # Build the endpoint URL
            endpoint = f"{self.sf_base_url}/services/apexrest/agent/{endpoint_name}"
            
            # Prepare headers
            headers = {
                'Authorization': f'Bearer {self.sf_access_token}',
                'Content-Type': 'application/json'
            }
            
            # Make the request
            response = requests.post(endpoint, json=params, headers=headers, timeout=30)
            
            if response.status_code == 200:
                return {
                    "status": "success",
                    "message": f"{endpoint_name} completed",
                    "parameters": params,
                    "salesforce_response": response.json() if response.content else "No content"
                }
            else:
                return {
                    "status": "error",
                    "message": f"Salesforce API error: {response.status_code}",
                    "error": response.text,
                    "parameters": params
                }
                
        except requests.exceptions.RequestException as e:
            logger.error(f"Salesforce API request failed: {e}")
            return {"error": f"Salesforce API request failed: {str(e)}"}
        except Exception as e:
            logger.error(f"Error calling Salesforce: {e}")
            return {"error": f"Salesforce integration error: {str(e)}"}

    def run(self, host: str = 'localhost', port: int = 8787):
        """Run the Flask server"""
        logger.info(f"Starting Comprehensive MCP server on {host}:{port}")
        logger.info(f"Dry run mode: {self.dry_run}")
        logger.info(f"Salesforce configured: {bool(self.sf_base_url and self.sf_access_token)}")
        logger.info(f"Supported tools: {list(self.router.tool_patterns.keys())}")
        
        self.app.run(host=host, port=port, debug=False)

def main():
    """Main function with CLI support"""
    parser = argparse.ArgumentParser(description='Comprehensive MCP Server')
    parser.add_argument('--port', type=int, default=8787, help='Port to run server on')
    parser.add_argument('--host', default='localhost', help='Host to bind to')
    parser.add_argument('--dry-run', action='store_true', help='Run in dry-run mode (default: True)')
    parser.add_argument('--live', action='store_true', help='Run in live mode (calls Salesforce)')
    
    args = parser.parse_args()
    
    # Load environment variables
    load_dotenv()
    
    # Get configuration from environment
    sf_base_url = os.getenv('SF_BASE_URL')
    sf_access_token = os.getenv('SF_ACCESS_TOKEN')
    # Determine dry run mode: --live overrides --dry-run, environment variable is fallback
    if args.live:
        dry_run = False
    elif args.dry_run:
        dry_run = True
    else:
        dry_run = os.getenv('DRY_RUN', 'true').lower() == 'true'
    port = int(os.getenv('PORT', args.port))
    host = os.getenv('HOST', args.host)
    
    # Start the server
    server = ComprehensiveMCPServer(
        dry_run=dry_run,
        sf_base_url=sf_base_url,
        sf_access_token=sf_access_token
    )
    server.run(host=host, port=port)

if __name__ == "__main__":
    main()
